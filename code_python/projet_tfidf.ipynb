{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports nécessaires\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Suppression de l'affichage des messages d'avertissement\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import string\n",
    "import time\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import set_config\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import FunctionTransformer, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "from keras.layers import TextVectorization\n",
    "from keras.layers import Embedding\n",
    "from spacy.lang.fr import French \n",
    "\n",
    "\n",
    "# Pour éviter l'affichage tronqué des descriptions\n",
    "pd.set_option('display.max_colwidth', -1) \n",
    "# Pour la visualisation des pipelines sklearn\n",
    "set_config(display='diagram') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définition de fonction utile par la suite:\n",
    "text_stats permet de compter le nombres de phrases dans synopsis et sera utilisé dans l'entrainement et\n",
    "split_into_tokens_steam permet de séparé le texte en token et fait la désuffixation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = FrenchStemmer()\n",
    "def text_stats(synopsis):\n",
    "    return [{\"length\": len(text), \"num_sentences\": text.count(\".\")} \n",
    "            for text in synopsis]\n",
    "# Split les différent token et réalise la désuffixation\n",
    "def split_into_tokens_steam(text):\n",
    "    steam = []\n",
    "    L = text.split()\n",
    "    for word in L:\n",
    "        steam.append(stemmer.stem(word))\n",
    "    return steam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on lit le fichier csv\n",
    "film_df = pd.read_csv(\"allocine_genres_train.csv\", sep=\",\")\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les colonnes contenant les informations utilisées pour l'apprentissage\n",
    "X = film_df[['titre', 'synopsis']]\n",
    "# La colonne contenant l'information à prédire\n",
    "y = film_df.genre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des mots vides de NLTK pour français + signes de ponctuation\n",
    "nltk_stopwords = stopwords.words('french')+list(string.punctuation)\n",
    "#on définit les différents objets qui vont être utilisé lors de l'apprentissage\n",
    "desc_vectorizer_classique_synopsis = TfidfVectorizer(tokenizer = lambda x : str.split(x, ' '), stop_words=nltk_stopwords,lowercase=True, min_df=0.01,sublinear_tf=False, use_idf=False, smooth_idf=False)\n",
    "desc_vectorizer_classique_titre = TfidfVectorizer(tokenizer = lambda x : str.split(x, ' '), stop_words=nltk_stopwords,lowercase=True,sublinear_tf=False, use_idf=False, smooth_idf=False)\n",
    "desc_vectorizer_steam_synopsis = TfidfVectorizer(tokenizer = split_into_tokens_steam, stop_words=nltk_stopwords,lowercase=True, min_df=0.01,sublinear_tf=False, use_idf=False, smooth_idf=False)\n",
    "desc_vectorizer_steam_titre = TfidfVectorizer(tokenizer = split_into_tokens_steam, stop_words=nltk_stopwords,lowercase=True,sublinear_tf=False, use_idf=False, smooth_idf=False)\n",
    "\n",
    "\n",
    "text_stats_transformer = FunctionTransformer(text_stats)\n",
    "text_stats_vectorizer = DictVectorizer(sparse=False)\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Modèles à comparer\n",
    "models = [\n",
    "    ('Baseline', DummyClassifier(strategy='most_frequent')),\n",
    "    ('Mutinomial NB', MultinomialNB()),\n",
    "    ('CART', DecisionTreeClassifier()),\n",
    "    ('LR', LogisticRegression()),\n",
    "    ('KNN', KNeighborsClassifier()),\n",
    "    ('Random forest', RandomForestClassifier())\n",
    "]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise la vectorisation sans désuffixation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_trans = ColumnTransformer(\n",
    "     [\n",
    "         ('titre_tfidf', desc_vectorizer_classique_titre, 'titre'),\n",
    "         # Colonne 'synopsis' : tf-idf\n",
    "         ('synopsis_tfidf', desc_vectorizer_classique_synopsis, 'synopsis'),\n",
    "         # Colonne 'synopsis' : statistiques\n",
    "         (\n",
    "             'synopsis_stats',\n",
    "             Pipeline(\n",
    "                 [\n",
    "                     ('text_stats', text_stats_transformer),\n",
    "                     ('vect', text_stats_vectorizer),\n",
    "                     ('scaling', min_max_scaler)\n",
    "                 ]\n",
    "             ), \n",
    "             'synopsis'\n",
    "         )\n",
    "     ],\n",
    ")\n",
    "# Evaluation de chaque résultat l'un après l'autre\n",
    "scores = []\n",
    "names = []\n",
    "scoring = 'macro F1'\n",
    "# Validation croisée à 5 plis\n",
    "kfold = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=12)\n",
    "# Itération sur les modèles\n",
    "for name, model in models:\n",
    "    # Ajout du nom du modèle à la liste name\n",
    "    names.append(name)\n",
    "    # Création de la pipeline pour le modèle\n",
    "    model_pipeline = make_pipeline(column_trans, model)\n",
    "    # Validation croisée\n",
    "    y_pred = model_selection.cross_val_predict(model_pipeline, \n",
    "                                               X, y, \n",
    "                                               cv=kfold)\n",
    "    print(name)\n",
    "    print(classification_report(y, y_pred))\n",
    "    f1 = metrics.f1_score(y, y_pred, average='macro')\n",
    "    scores.append(f1)\n",
    "\n",
    "# Représentation graphique des résultats\n",
    "indices = np.arange(len(scores))\n",
    "fig = plt.figure()\n",
    "plt.barh(indices, scores, .2, label=\"score\", color='b')\n",
    "plt.yticks(())\n",
    "for i, c in zip(indices, names):\n",
    "    plt.text(-.3, i, c)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise des vecteurs avec désuffixation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_trans = ColumnTransformer(\n",
    "     [\n",
    "         ('titre_tfidf', desc_vectorizer_steam_titre, 'titre'),\n",
    "         # Colonne 'synopsis' : tf-idf\n",
    "         ('synopsis_tfidf', desc_vectorizer_steam_synopsis, 'synopsis'),\n",
    "         # Colonne 'synopsis' : statistiques\n",
    "         (\n",
    "             'synopsis_stats',\n",
    "             Pipeline(\n",
    "                 [\n",
    "                     ('text_stats', text_stats_transformer),\n",
    "                     ('vect', text_stats_vectorizer),\n",
    "                     ('scaling', min_max_scaler)\n",
    "                 ]\n",
    "             ), \n",
    "             'synopsis'\n",
    "         )\n",
    "     ],\n",
    ")\n",
    "# Evaluation de chaque résultat l'un après l'autre\n",
    "scores = []\n",
    "names = []\n",
    "scoring = 'macro F1'\n",
    "# Validation croisée à 5 plis\n",
    "kfold = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=12)\n",
    "# Itération sur les modèles\n",
    "for name, model in models:\n",
    "    # Ajout du nom du modèle à la liste name\n",
    "    names.append(name)\n",
    "    # Création de la pipeline pour le modèle\n",
    "    model_pipeline = make_pipeline(column_trans, model)\n",
    "    # Validation croisée\n",
    "    y_pred = model_selection.cross_val_predict(model_pipeline, \n",
    "                                               X, y, \n",
    "                                               cv=kfold)\n",
    "    print(name)\n",
    "    print(classification_report(y, y_pred))\n",
    "    f1 = metrics.f1_score(y, y_pred, average='macro')\n",
    "    scores.append(f1)\n",
    "\n",
    "# Représentation graphique des résultats\n",
    "indices = np.arange(len(scores))\n",
    "fig = plt.figure()\n",
    "plt.barh(indices, scores, .2, label=\"score\", color='b')\n",
    "plt.yticks(())\n",
    "for i, c in zip(indices, names):\n",
    "    plt.text(-.3, i, c)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
